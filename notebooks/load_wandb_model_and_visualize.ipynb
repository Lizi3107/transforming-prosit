{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1dfefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 10:11:00.919767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 10:11:01.739777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from dlomix.losses import masked_spectral_distance, masked_pearson_correlation_distance\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a022be",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"transforming-prosit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e659fd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmamisashvili-lizi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/cmnfs/home/l.mamisashvili/transforming-prosit/notebooks/wandb/run-20230605_101104-6xorqqxg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mamisashvili-lizi/transforming-prosit/runs/6xorqqxg' target=\"_blank\">pious-river-41</a></strong> to <a href='https://wandb.ai/mamisashvili-lizi/transforming-prosit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mamisashvili-lizi/transforming-prosit' target=\"_blank\">https://wandb.ai/mamisashvili-lizi/transforming-prosit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mamisashvili-lizi/transforming-prosit/runs/6xorqqxg' target=\"_blank\">https://wandb.ai/mamisashvili-lizi/transforming-prosit/runs/6xorqqxg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3674ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact_name = \"mamisashvili-lizi/transforming-prosit/model-transformers_v2:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950c1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.use_artifact(model_artifact_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4c9aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   5 of 5 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "model_dir = model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4f52d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./artifacts/model-transformers_v2:v0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ffc9b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 08:32:16.359177: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 08:32:16.605682: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-09 08:32:17.490745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-09 08:32:17.490977: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-09 08:32:17.490983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-06-09 08:32:28.170206: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 08:32:29.443780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 28740 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2023-06-09 08:32:29.448354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 43648 MB memory:  -> device: 1, name: NVIDIA A40, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2023-06-09 08:32:29.451911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 43648 MB memory:  -> device: 2, name: NVIDIA A40, pci bus id: 0000:e2:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from dlomix.data import IntensityDataset\n",
    "\n",
    "TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/Intensity/proteomeTools_train_val.csv'\n",
    "BATCH_SIZE = 64\n",
    "int_data = IntensityDataset(data_source=TRAIN_DATAPATH, seq_length=30,\n",
    "                            collision_energy_col='collision_energy', batch_size=BATCH_SIZE, val_ratio=0.2, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3283776e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Training examples', 23616, 'Validation examples', 5952)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Training examples\", BATCH_SIZE * len(int_data.train_data), \"Validation examples\", BATCH_SIZE * len(int_data.val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803d4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_dir, custom_objects={\n",
    "    \"masked_spectral_distance\": masked_spectral_distance,\n",
    "    \"masked_pearson_correlation_distance\": masked_pearson_correlation_distance\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "499a8f7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"prosit_transformer_intensity_predictor_v2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " meta_encoder (MetaEncoder)  multiple                  128       \n",
      "                                                                 \n",
      " string_lookup (StringLookup  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " embedding (Embedding)       multiple                  352       \n",
      "                                                                 \n",
      " encoder_att (AttentionLayer  multiple                 46        \n",
      " )                                                               \n",
      "                                                                 \n",
      " fusion_layer (FusionLayer)  multiple                  0         \n",
      "                                                                 \n",
      " sequence_encoder_no_gru (Se  multiple                 54192     \n",
      " quenceEncoderNoGRU)                                             \n",
      "                                                                 \n",
      " transformer_decoder (Transf  multiple                 55062     \n",
      " ormerDecoder)                                                   \n",
      "                                                                 \n",
      " regressor (Regressor)       multiple                  102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,882\n",
      "Trainable params: 109,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87396b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
